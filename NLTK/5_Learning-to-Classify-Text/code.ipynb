{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification\n",
    "\n",
    "![classifier](images/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Classification is the task of choosing the correct class label for a given input. In basic\n",
    "classification tasks, each input is considered in isolation from all other inputs, and the\n",
    "set of labels is defined in advance. Some examples of classification tasks are:\n",
    "\n",
    "• Deciding whether an email is spam or not.\n",
    "• Deciding what the topic of a news article is, from a fixed list of topic areas such as\n",
    "“sports,” “technology,” and “politics.”\n",
    "• Deciding whether a given occurrence of the word bank is used to refer to a river\n",
    "bank, a financial institution, the act of tilting to the side, or the act of depositing\n",
    "something in a financial institution.\n",
    "\n",
    "'''\n",
    "\n",
    "# Gender Identification\n",
    "\n",
    "''' \n",
    "Names ending in a, e, and i are likely to be female, while names ending in k, o, r, s, and\n",
    "t are likely to be male. Let’s build a classifier to model these differences more precisely.\n",
    "'''\n",
    "\n",
    "''' \n",
    "The first step in creating a classifier is deciding what features of the input are relevant,\n",
    "and how to encode those features.\n",
    "'''\n",
    "import nltk\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1],\n",
    "            'first_letter': word[0],\n",
    "            'length': len(word),\n",
    "            'first_vowel': first_vowel(word),\n",
    "            'second_letter': word[1] if len(word)>1 else ''\n",
    "            }\n",
    "\n",
    "def first_vowel(word):\n",
    "    for letter in word:\n",
    "        if letter in 'aeiouAEIOU':\n",
    "            return letter\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'n',\n",
       " 'first_letter': 'A',\n",
       " 'length': 5,\n",
       " 'first_vowel': 'A',\n",
       " 'second_letter': 'n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('Anson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Harry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Praveen'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'k'              male : female =     44.5 : 1.0\n",
      "             last_letter = 'a'            female : male   =     33.0 : 1.0\n",
      "             last_letter = 'f'              male : female =     17.3 : 1.0\n",
      "           second_letter = 'k'              male : female =     15.3 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "When working with large corpora, constructing a single list that contains the features\n",
    "of every instance can use up a large amount of memory. In these cases, use the function\n",
    "nltk.classify.apply_features, which returns an object that acts like a list but does not\n",
    "store all the feature sets in memory\n",
    "'''\n",
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(gender_features, names[500:])\n",
    "test_set = apply_features(gender_features, names[:500])\n",
    "\n",
    "# pg 224 - choosing the right features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
