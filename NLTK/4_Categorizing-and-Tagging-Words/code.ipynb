{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing and Tagging Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "The process of classifying words into their parts-of-speech and labeling them accordingly\n",
    "is known as part-of-speech tagging, POS tagging, or simply tagging. Partsof-\n",
    "speech are also known as word classes or lexical categories. The collection of tags\n",
    "used for a particular task is known as a tagset. Our emphasis in this chapter is on\n",
    "exploiting tags, and tagging text automatically.\n",
    "'''\n",
    "\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Here we see that and is CC, a coordinating conjunction; now and completely are RB, or\n",
    "adverbs; for is IN, a preposition; something is NN, a noun; and different is JJ, an adjective.\n",
    "'''\n",
    "\n",
    "''' \n",
    "The text.similar() method takes a word w, finds all contexts w1w w2,\n",
    "then finds all words w' that appear in the same context, i.e. w1w'w2.\n",
    "'''\n",
    "\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simplified Part-of-Speech Tagset\n",
    "\n",
    "![POS-Table](images/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'VBD', 'NR', 'NN', 'IN', 'NP$', 'JJ', '``', \"''\", 'CS', 'DTI', 'NNS', '.', 'RBR', ',', 'WDT', 'HVD', 'VBZ', 'CC', 'IN-TL', 'BEDZ', 'VBN', 'NP', 'BEN', 'TO', 'VB', 'RB', 'DT', 'PPS', 'DOD', 'AP', 'BER', 'HV', 'DTS', 'VBG', 'PPO', 'QL', 'JJT', 'ABX', 'NN-HL', 'VBN-HL', 'WRB', 'CD', 'MD', 'BE', 'JJR', 'VBG-TL', 'BEZ', 'NN$-TL', 'HVZ', 'ABN', 'PN', 'PPSS', 'PP$', 'DO', 'NN$', 'NNS-HL', 'WPS', '*', 'EX', 'VB-HL', ':', '(', ')', 'NNS-TL', 'NPS', 'JJS', 'RP', '--', 'BED', 'OD', 'BEG', 'AT-HL', 'VBG-HL', 'AT-TL', 'PPL', 'DOZ', 'NP-HL', 'NR$', 'DOD*', 'BEDZ*', ',-HL', 'CC-TL', 'MD*', 'NNS$', 'PPSS+BER', \"'\", 'PPSS+BEM', 'CD-TL', 'RBT', '(-HL', ')-HL', 'MD-HL', 'VBZ-HL', 'IN-HL', 'JJ-HL', 'PPLS', 'CD-HL', 'WPO', 'JJS-TL', 'ABL', 'BER-HL', 'PPS+HVZ', 'VBD-HL', 'RP-HL', 'MD*-HL', 'AP-HL', 'CS-HL', 'DT$', 'HVN', 'FW-IN', 'FW-DT', 'VBN-TL', 'NR-TL', 'NNS$-TL', 'FW-NN', 'HVG', 'DTX', 'OD-TL', 'BEM', 'RB-HL', 'PPSS+MD', 'NPS-HL', 'NPS$', 'WP$', 'NN-TL-HL', 'CC-HL', 'PPS+BEZ', 'AP-TL', 'UH-TL', 'BEZ-HL', 'TO-HL', 'DO*', 'VBN-TL-HL', 'NNS-TL-HL', 'DT-HL', 'BE-HL', 'DOZ*', 'QLP', 'JJR-HL', 'PPSS+HVD', 'FW-IN+NN', 'PP$$', 'JJT-HL', 'NP-TL-HL', 'NPS-TL', 'MD+HV', 'NP$-TL', 'OD-HL', 'JJR-TL', 'VBD-TL', 'DT+BEZ', 'EX+BEZ', 'PPSS+HV', ':-HL', 'PPS+MD', 'UH', 'FW-CC', 'FW-NNS', 'BEDZ-HL', 'NN$-HL', '.-HL', 'HVD*', 'BEZ*', 'AP$', 'NP+BEZ', 'FW-AT-TL', 'VB-TL', 'RB-TL', 'MD-TL', 'PN+HVZ', 'FW-JJ-TL', 'FW-NN-TL', 'ABN-HL', 'PPS+BEZ-HL', 'NR-HL', 'HVD-HL', 'RB$', 'FW-AT-HL', 'DO-HL', 'PP$-TL', 'FW-IN-TL', 'WPS+BEZ', '*-HL', 'DTI-HL', 'PN-HL', 'CD$', 'BER*', 'NNS$-HL', 'PN$', 'BER-TL', 'TO-TL', 'FW-JJ', 'BED*', 'RB+BEZ', 'VB+PPO', 'PPSS-HL', 'HVZ*', 'FW-IN+NN-TL', 'FW-IN+AT-TL', 'NN-NC', 'JJ-NC', 'NR$-TL', 'FW-PP$-NC', 'FW-VB', 'FW-VB-NC', 'JJR-NC', 'NPS$-TL', 'QL-TL', 'FW-AT', 'FW-*', 'FW-CD', 'WQL', 'FW-WDT', 'WDT+BEZ'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "tag_fd.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "If we try to access a key that is not in a dictionary, we get an error. However, it’s often\n",
    "useful if a dictionary can automatically create an entry for this new key and give it a\n",
    "default value, such as zero or the empty list. Since Python 2.5, a special kind of dictionary\n",
    "called a defaultdict has been available. (It is provided as nltk.defaultdict for\n",
    "the benefit of readers who are using Python 2.4.) In order to use it, we have to supply\n",
    "a parameter which can be used to create the default value, e.g., int, float, str, list,\n",
    "dict, tuple.\n",
    "'''\n",
    "\n",
    "frequency = nltk.defaultdict(int)\n",
    "frequency['colorless'] = 5\n",
    "frequency['ideas'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Alice',\n",
       " \"'\",\n",
       " 's',\n",
       " 'Adventures',\n",
       " 'in',\n",
       " 'Wonderland',\n",
       " 'by',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'UNK',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " '.',\n",
       " 'Down',\n",
       " 'the',\n",
       " 'Rabbit',\n",
       " '-',\n",
       " 'UNK',\n",
       " 'Alice',\n",
       " 'was',\n",
       " 'beginning',\n",
       " 'to',\n",
       " 'get',\n",
       " 'very',\n",
       " 'tired',\n",
       " 'of',\n",
       " 'sitting',\n",
       " 'by',\n",
       " 'her',\n",
       " 'sister',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bank',\n",
       " ',',\n",
       " 'and',\n",
       " 'of',\n",
       " 'having',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " ':',\n",
       " 'once',\n",
       " 'or',\n",
       " 'twice',\n",
       " 'she',\n",
       " 'had',\n",
       " 'peeped',\n",
       " 'into',\n",
       " 'the',\n",
       " 'book',\n",
       " 'her',\n",
       " 'sister',\n",
       " 'was',\n",
       " 'reading',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'had',\n",
       " 'no',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'UNK',\n",
       " 'in',\n",
       " 'it',\n",
       " ',',\n",
       " \"'\",\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'a',\n",
       " 'book',\n",
       " \",'\",\n",
       " 'thought',\n",
       " 'Alice',\n",
       " \"'\",\n",
       " 'without',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversation',\n",
       " \"?'\",\n",
       " 'So',\n",
       " 'she',\n",
       " 'was',\n",
       " 'considering',\n",
       " 'in',\n",
       " 'her',\n",
       " 'own',\n",
       " 'mind',\n",
       " '(',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'she',\n",
       " 'could',\n",
       " ',']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "We need to create a default dictionary that maps each word to its replacement. The\n",
    "most frequent n words will be mapped to themselves. Everything else will be mapped\n",
    "to UNK.\n",
    "'''\n",
    "\n",
    "alice = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "vocab = nltk.FreqDist(alice)\n",
    "v1000 = list(vocab)[:1000]\n",
    "mapping = nltk.defaultdict(lambda: 'UNK')\n",
    "for v in v1000:\n",
    "    mapping[v] = v\n",
    "alice2 = [mapping[v] for v in alice]\n",
    "alice2[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incrementally Updating a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13162"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We can employ dictionaries to count occurrences, emulating the method for tallying\n",
    "words shown in Figure 1-3. We begin by initializing an empty defaultdict, then process\n",
    "each part-of-speech tag in the text. If the tag hasn’t been seen before, it will have a zero\n",
    "count by default. Each time we encounter a tag, we increment its count using the +=\n",
    "operator\n",
    "'''\n",
    "\n",
    "counts = nltk.defaultdict(int)\n",
    "from nltk.corpus import brown\n",
    "\n",
    "for(word, tag) in brown.tagged_words(categories='news'):\n",
    "    counts[tag] += 1\n",
    "    \n",
    "counts['NN']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AT',\n",
       " 'NP-TL',\n",
       " 'NN-TL',\n",
       " 'JJ-TL',\n",
       " 'VBD',\n",
       " 'NR',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NP$',\n",
       " 'JJ',\n",
       " '``',\n",
       " \"''\",\n",
       " 'CS',\n",
       " 'DTI',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'RBR',\n",
       " ',',\n",
       " 'WDT',\n",
       " 'HVD',\n",
       " 'VBZ',\n",
       " 'CC',\n",
       " 'IN-TL',\n",
       " 'BEDZ',\n",
       " 'VBN',\n",
       " 'NP',\n",
       " 'BEN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'DT',\n",
       " 'PPS',\n",
       " 'DOD',\n",
       " 'AP',\n",
       " 'BER',\n",
       " 'HV',\n",
       " 'DTS',\n",
       " 'VBG',\n",
       " 'PPO',\n",
       " 'QL',\n",
       " 'JJT',\n",
       " 'ABX',\n",
       " 'NN-HL',\n",
       " 'VBN-HL',\n",
       " 'WRB',\n",
       " 'CD',\n",
       " 'MD',\n",
       " 'BE',\n",
       " 'JJR',\n",
       " 'VBG-TL',\n",
       " 'BEZ',\n",
       " 'NN$-TL',\n",
       " 'HVZ',\n",
       " 'ABN',\n",
       " 'PN',\n",
       " 'PPSS',\n",
       " 'PP$',\n",
       " 'DO',\n",
       " 'NN$',\n",
       " 'NNS-HL',\n",
       " 'WPS',\n",
       " '*',\n",
       " 'EX',\n",
       " 'VB-HL',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " 'NNS-TL',\n",
       " 'NPS',\n",
       " 'JJS',\n",
       " 'RP',\n",
       " '--',\n",
       " 'BED',\n",
       " 'OD',\n",
       " 'BEG',\n",
       " 'AT-HL',\n",
       " 'VBG-HL',\n",
       " 'AT-TL',\n",
       " 'PPL',\n",
       " 'DOZ',\n",
       " 'NP-HL',\n",
       " 'NR$',\n",
       " 'DOD*',\n",
       " 'BEDZ*',\n",
       " ',-HL',\n",
       " 'CC-TL',\n",
       " 'MD*',\n",
       " 'NNS$',\n",
       " 'PPSS+BER',\n",
       " \"'\",\n",
       " 'PPSS+BEM',\n",
       " 'CD-TL',\n",
       " 'RBT',\n",
       " '(-HL',\n",
       " ')-HL',\n",
       " 'MD-HL',\n",
       " 'VBZ-HL',\n",
       " 'IN-HL',\n",
       " 'JJ-HL',\n",
       " 'PPLS',\n",
       " 'CD-HL',\n",
       " 'WPO',\n",
       " 'JJS-TL',\n",
       " 'ABL',\n",
       " 'BER-HL',\n",
       " 'PPS+HVZ',\n",
       " 'VBD-HL',\n",
       " 'RP-HL',\n",
       " 'MD*-HL',\n",
       " 'AP-HL',\n",
       " 'CS-HL',\n",
       " 'DT$',\n",
       " 'HVN',\n",
       " 'FW-IN',\n",
       " 'FW-DT',\n",
       " 'VBN-TL',\n",
       " 'NR-TL',\n",
       " 'NNS$-TL',\n",
       " 'FW-NN',\n",
       " 'HVG',\n",
       " 'DTX',\n",
       " 'OD-TL',\n",
       " 'BEM',\n",
       " 'RB-HL',\n",
       " 'PPSS+MD',\n",
       " 'NPS-HL',\n",
       " 'NPS$',\n",
       " 'WP$',\n",
       " 'NN-TL-HL',\n",
       " 'CC-HL',\n",
       " 'PPS+BEZ',\n",
       " 'AP-TL',\n",
       " 'UH-TL',\n",
       " 'BEZ-HL',\n",
       " 'TO-HL',\n",
       " 'DO*',\n",
       " 'VBN-TL-HL',\n",
       " 'NNS-TL-HL',\n",
       " 'DT-HL',\n",
       " 'BE-HL',\n",
       " 'DOZ*',\n",
       " 'QLP',\n",
       " 'JJR-HL',\n",
       " 'PPSS+HVD',\n",
       " 'FW-IN+NN',\n",
       " 'PP$$',\n",
       " 'JJT-HL',\n",
       " 'NP-TL-HL',\n",
       " 'NPS-TL',\n",
       " 'MD+HV',\n",
       " 'NP$-TL',\n",
       " 'OD-HL',\n",
       " 'JJR-TL',\n",
       " 'VBD-TL',\n",
       " 'DT+BEZ',\n",
       " 'EX+BEZ',\n",
       " 'PPSS+HV',\n",
       " ':-HL',\n",
       " 'PPS+MD',\n",
       " 'UH',\n",
       " 'FW-CC',\n",
       " 'FW-NNS',\n",
       " 'BEDZ-HL',\n",
       " 'NN$-HL',\n",
       " '.-HL',\n",
       " 'HVD*',\n",
       " 'BEZ*',\n",
       " 'AP$',\n",
       " 'NP+BEZ',\n",
       " 'FW-AT-TL',\n",
       " 'VB-TL',\n",
       " 'RB-TL',\n",
       " 'MD-TL',\n",
       " 'PN+HVZ',\n",
       " 'FW-JJ-TL',\n",
       " 'FW-NN-TL',\n",
       " 'ABN-HL',\n",
       " 'PPS+BEZ-HL',\n",
       " 'NR-HL',\n",
       " 'HVD-HL',\n",
       " 'RB$',\n",
       " 'FW-AT-HL',\n",
       " 'DO-HL',\n",
       " 'PP$-TL',\n",
       " 'FW-IN-TL',\n",
       " 'WPS+BEZ',\n",
       " '*-HL',\n",
       " 'DTI-HL',\n",
       " 'PN-HL',\n",
       " 'CD$',\n",
       " 'BER*',\n",
       " 'NNS$-HL',\n",
       " 'PN$',\n",
       " 'BER-TL',\n",
       " 'TO-TL',\n",
       " 'FW-JJ',\n",
       " 'BED*',\n",
       " 'RB+BEZ',\n",
       " 'VB+PPO',\n",
       " 'PPSS-HL',\n",
       " 'HVZ*',\n",
       " 'FW-IN+NN-TL',\n",
       " 'FW-IN+AT-TL',\n",
       " 'NN-NC',\n",
       " 'JJ-NC',\n",
       " 'NR$-TL',\n",
       " 'FW-PP$-NC',\n",
       " 'FW-VB',\n",
       " 'FW-VB-NC',\n",
       " 'JJR-NC',\n",
       " 'NPS$-TL',\n",
       " 'QL-TL',\n",
       " 'FW-AT',\n",
       " 'FW-*',\n",
       " 'FW-CD',\n",
       " 'WQL',\n",
       " 'FW-WDT',\n",
       " 'WDT+BEZ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 13162),\n",
       " ('IN', 10616),\n",
       " ('AT', 8893),\n",
       " ('NP', 6866),\n",
       " (',', 5133),\n",
       " ('NNS', 5066),\n",
       " ('.', 4452),\n",
       " ('JJ', 4392),\n",
       " ('CC', 2664),\n",
       " ('VBD', 2524),\n",
       " ('NN-TL', 2486),\n",
       " ('VB', 2440),\n",
       " ('VBN', 2269),\n",
       " ('RB', 2166),\n",
       " ('CD', 2020),\n",
       " ('CS', 1509),\n",
       " ('VBG', 1398),\n",
       " ('TO', 1237),\n",
       " ('PPS', 1056),\n",
       " ('PP$', 1051),\n",
       " ('MD', 1031),\n",
       " ('AP', 923),\n",
       " ('NP-TL', 741),\n",
       " ('``', 732),\n",
       " ('BEZ', 730),\n",
       " ('BEDZ', 716),\n",
       " (\"''\", 702),\n",
       " ('JJ-TL', 689),\n",
       " ('PPSS', 602),\n",
       " ('DT', 589),\n",
       " ('BE', 525),\n",
       " ('VBZ', 519),\n",
       " ('NR', 495),\n",
       " ('RP', 482),\n",
       " ('QL', 468),\n",
       " ('PPO', 412),\n",
       " ('WPS', 395),\n",
       " ('NNS-TL', 344),\n",
       " ('WDT', 343),\n",
       " ('BER', 328),\n",
       " ('WRB', 328),\n",
       " ('OD', 309),\n",
       " ('HVZ', 301),\n",
       " ('--', 300),\n",
       " ('NP$', 279),\n",
       " ('HV', 265),\n",
       " ('HVD', 262),\n",
       " ('*', 256),\n",
       " ('BED', 252),\n",
       " ('NPS', 215),\n",
       " ('BEN', 212),\n",
       " ('NN$', 210),\n",
       " ('DTI', 205),\n",
       " ('NP-HL', 186),\n",
       " ('ABN', 183),\n",
       " ('NN-HL', 171),\n",
       " ('IN-TL', 164),\n",
       " ('EX', 161),\n",
       " (')', 151),\n",
       " ('(', 148),\n",
       " ('JJR', 145),\n",
       " (':', 137),\n",
       " ('DTS', 136),\n",
       " ('JJT', 100),\n",
       " ('CD-TL', 96),\n",
       " ('NNS-HL', 92),\n",
       " ('PN', 89),\n",
       " ('RBR', 88),\n",
       " ('VBN-TL', 87),\n",
       " ('ABX', 73),\n",
       " ('NN$-TL', 69),\n",
       " ('IN-HL', 65),\n",
       " ('DOD', 64),\n",
       " ('DO', 63),\n",
       " ('BEG', 57),\n",
       " (',-HL', 55),\n",
       " ('VBN-HL', 53),\n",
       " ('AT-TL', 50),\n",
       " ('NNS$', 50),\n",
       " ('CD-HL', 50),\n",
       " ('JJS', 49),\n",
       " ('CC-TL', 46),\n",
       " (\"'\", 46),\n",
       " ('JJ-HL', 46),\n",
       " ('MD*', 43),\n",
       " ('VBZ-HL', 39),\n",
       " ('PPL', 36),\n",
       " ('PPSS+MD', 31),\n",
       " ('PPS+BEZ', 31),\n",
       " ('OD-TL', 30),\n",
       " ('DOZ', 26),\n",
       " ('VB-HL', 25),\n",
       " ('NR$', 24),\n",
       " ('FW-NN', 22),\n",
       " ('WP$', 22),\n",
       " ('PPLS', 21),\n",
       " ('ABL', 21),\n",
       " ('PPSS+BER', 20),\n",
       " ('(-HL', 20),\n",
       " (')-HL', 20),\n",
       " ('NNS$-TL', 20),\n",
       " ('.-HL', 20),\n",
       " ('PPSS+HV', 19),\n",
       " ('PPSS+BEM', 18),\n",
       " ('HVN', 18),\n",
       " ('NPS$', 17),\n",
       " ('DO*', 17),\n",
       " ('FW-NN-TL', 16),\n",
       " ('VBG-TL', 15),\n",
       " ('DOD*', 15),\n",
       " ('RB-HL', 15),\n",
       " ('NPS-TL', 15),\n",
       " ('AT-HL', 14),\n",
       " ('FW-IN', 14),\n",
       " ('NR-TL', 14),\n",
       " ('HVG', 14),\n",
       " ('BEM', 13),\n",
       " ('DOZ*', 13),\n",
       " ('VBG-HL', 12),\n",
       " ('NN-TL-HL', 12),\n",
       " ('QLP', 12),\n",
       " ('DT+BEZ', 12),\n",
       " (':-HL', 12),\n",
       " ('UH', 12),\n",
       " ('FW-JJ-TL', 12),\n",
       " ('NP$-TL', 11),\n",
       " ('WPO', 9),\n",
       " ('DTX', 8),\n",
       " ('PPS+MD', 8),\n",
       " ('BEZ*', 8),\n",
       " ('VB-TL', 8),\n",
       " ('RB-TL', 8),\n",
       " ('AP-HL', 7),\n",
       " ('CC-HL', 7),\n",
       " ('VBD-HL', 6),\n",
       " ('TO-HL', 6),\n",
       " ('FW-AT-TL', 6),\n",
       " ('RBT', 5),\n",
       " ('MD-HL', 5),\n",
       " ('PPS+HVZ', 4),\n",
       " ('RP-HL', 4),\n",
       " ('JJR-HL', 4),\n",
       " ('JJR-TL', 4),\n",
       " ('BER*', 4),\n",
       " ('BEDZ*', 3),\n",
       " ('NPS-HL', 3),\n",
       " ('BEZ-HL', 3),\n",
       " ('PP$$', 3),\n",
       " ('FW-JJ', 3),\n",
       " ('NN-NC', 3),\n",
       " ('FW-AT', 3),\n",
       " ('JJS-TL', 2),\n",
       " ('FW-IN+NN', 2),\n",
       " ('JJT-HL', 2),\n",
       " ('EX+BEZ', 2),\n",
       " ('FW-NNS', 2),\n",
       " ('NN$-HL', 2),\n",
       " ('HVD*', 2),\n",
       " ('NR-HL', 2),\n",
       " ('WPS+BEZ', 2),\n",
       " ('DTI-HL', 2),\n",
       " ('CD$', 2),\n",
       " ('NNS$-HL', 2),\n",
       " ('BER-HL', 1),\n",
       " ('MD*-HL', 1),\n",
       " ('CS-HL', 1),\n",
       " ('DT$', 1),\n",
       " ('FW-DT', 1),\n",
       " ('AP-TL', 1),\n",
       " ('UH-TL', 1),\n",
       " ('VBN-TL-HL', 1),\n",
       " ('NNS-TL-HL', 1),\n",
       " ('DT-HL', 1),\n",
       " ('BE-HL', 1),\n",
       " ('PPSS+HVD', 1),\n",
       " ('NP-TL-HL', 1),\n",
       " ('MD+HV', 1),\n",
       " ('OD-HL', 1),\n",
       " ('VBD-TL', 1),\n",
       " ('FW-CC', 1),\n",
       " ('BEDZ-HL', 1),\n",
       " ('AP$', 1),\n",
       " ('NP+BEZ', 1),\n",
       " ('MD-TL', 1),\n",
       " ('PN+HVZ', 1),\n",
       " ('ABN-HL', 1),\n",
       " ('PPS+BEZ-HL', 1),\n",
       " ('HVD-HL', 1),\n",
       " ('RB$', 1),\n",
       " ('FW-AT-HL', 1),\n",
       " ('DO-HL', 1),\n",
       " ('PP$-TL', 1),\n",
       " ('FW-IN-TL', 1),\n",
       " ('*-HL', 1),\n",
       " ('PN-HL', 1),\n",
       " ('PN$', 1),\n",
       " ('BER-TL', 1),\n",
       " ('TO-TL', 1),\n",
       " ('BED*', 1),\n",
       " ('RB+BEZ', 1),\n",
       " ('VB+PPO', 1),\n",
       " ('PPSS-HL', 1),\n",
       " ('HVZ*', 1),\n",
       " ('FW-IN+NN-TL', 1),\n",
       " ('FW-IN+AT-TL', 1),\n",
       " ('JJ-NC', 1),\n",
       " ('NR$-TL', 1),\n",
       " ('FW-PP$-NC', 1),\n",
       " ('FW-VB', 1),\n",
       " ('FW-VB-NC', 1),\n",
       " ('JJR-NC', 1),\n",
       " ('NPS$-TL', 1),\n",
       " ('QL-TL', 1),\n",
       " ('FW-*', 1),\n",
       " ('FW-CD', 1),\n",
       " ('WQL', 1),\n",
       " ('FW-WDT', 1),\n",
       " ('WDT+BEZ', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "sorted(counts.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Tagging\n",
    "\n",
    "### The Default Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The simplest possible tagger assigns the same tag to each token. This may seem to be\n",
    "a rather banal step, but it establishes an important baseline for tagger performance. In\n",
    "order to get the best result, we tag each word with the most likely tag.\n",
    "''' \n",
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "tags = [tag for(word, tag) in brown.tagged_words(categories='news')]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Sam', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN'),\n",
       " ('!', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can create a tagger that tags everything as NN.\n",
    "\n",
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5520/2293548747.py:14: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  regex_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20326391789486245"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The Regular Expression Tagger\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'), # gerunds\n",
    "    (r'.*ed$', 'VBD'), # simple past\n",
    "    (r'.*es$', 'VBZ'), # 3rd singular present\n",
    "    (r'.*ould$', 'MD'), # modals\n",
    "    (r'.*\\'s$', 'NN$'), # possessive nouns\n",
    "    (r'.*s$', 'NNS'), # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers\n",
    "    (r'.*', 'NN') # nouns (default)\n",
    "]\n",
    "\n",
    "regex_tagger = nltk.RegexpTagger(patterns)\n",
    "regex_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Tagging\n",
    "\n",
    "### Unigram Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'QL'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Unigram taggers are based on a simple statistical algorithm: for each token, assign the\n",
    "tag that is most likely for that particular token. For example, it will assign the tag JJ to\n",
    "any occurrence of the word frequent, since frequent is used as an adjective (e.g., a frequent\n",
    "word) more often than it is used as a verb (e.g., I frequent this cafe).\n",
    "'''\n",
    "\n",
    "# A unigram tagger behaves just like a lookup tagger, except there is a more convenient technique for setting it up, called training.\n",
    "\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5520/1449911821.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  unigram_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General N-Gram Tagging\n",
    "\n",
    "![tagger context](images/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "An n-gram tagger is a generalization of a unigram tagger whose context is the current\n",
    "word together with the part-of-speech tags of the n-1 preceding tokens\n",
    "'''\n",
    "'''\n",
    "The NgramTagger class uses a tagged training corpus to determine which part-of-speech\n",
    "tag is most likely for each context. Here we see a special case of an n-gram tagger,\n",
    "namely a bigram tagger.\n",
    "'''\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('population', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('Congo', 'NP'),\n",
       " ('is', 'BEZ'),\n",
       " ('13.5', None),\n",
       " ('million', None),\n",
       " (',', None),\n",
       " ('divided', None),\n",
       " ('into', None),\n",
       " ('at', None),\n",
       " ('least', None),\n",
       " ('seven', None),\n",
       " ('major', None),\n",
       " ('``', None),\n",
       " ('culture', None),\n",
       " ('clusters', None),\n",
       " (\"''\", None),\n",
       " ('and', None),\n",
       " ('innumerable', None),\n",
       " ('tribes', None),\n",
       " ('speaking', None),\n",
       " ('400', None),\n",
       " ('separate', None),\n",
       " ('dialects', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sent = brown_sents[4203]\n",
    "bigram_tagger.tag(unseen_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/anson/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/anson/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "/tmp/ipykernel_5520/1084139904.py:21: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(brill_tagger.evaluate(test_data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755018346643644\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')  # Ensure the corpus is available\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tag import brill, brill_trainer\n",
    "\n",
    "# Load sample data\n",
    "train_data = nltk.corpus.treebank.tagged_sents()[:3000]\n",
    "test_data = nltk.corpus.treebank.tagged_sents()[3000:]\n",
    "\n",
    "# Use a basic tagger as the initial tagger\n",
    "initial_tagger = nltk.tag.UnigramTagger(train_data)\n",
    "\n",
    "# Define a simple Brill tagging template\n",
    "templates = brill.brill24()\n",
    "\n",
    "# Train a Brill tagger using BrillTaggerTrainer\n",
    "trainer = brill_trainer.BrillTaggerTrainer(initial_tagger, templates)\n",
    "brill_tagger = trainer.train(train_data)\n",
    "\n",
    "# Test the Brill tagger\n",
    "print(brill_tagger.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
